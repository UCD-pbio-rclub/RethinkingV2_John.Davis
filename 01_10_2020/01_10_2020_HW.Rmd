---
title: "01_10_2020_HW"
author: "John D."
date: "1/6/2020"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(rethinking)
```

# Easy

### 12E1. Which of the following priors will produce more shrinkage in the estimates?

  __(a)__ $$\alpha_{tank} \sim Normal(0, 1) $$
  
  (b) $$\alpha_{tank} \sim Normal(0, 2) $$

```{r}
data(reedfrogs)
d <- reedfrogs
d$tank <- 1:nrow(d)

dat <- list(S = d$surv,
            N = d$density,
            tank = d$tank)

E12a <- ulam(
  alist(S ~ dbinom(N , p) ,
        logit(p) <- a[tank] ,
        a[tank] ~ dnorm(0 , 1)),
  data = dat ,
  chains = 1 ,
  cores = 4 ,
  log_lik = TRUE
)

E12b <- ulam(
  alist(S ~ dbinom(N , p) ,
        logit(p) <- a[tank] ,
        a[tank] ~ dnorm(0 , 2)),
  data = dat ,
  chains = 1 ,
  cores = 4 ,
  log_lik = TRUE
)

# extract Stan samples
posta <- extract.samples(E12a)
postb <- extract.samples(E12b)

# compute median intercept for each tank
# also transform to probability with logistic
d$propsurv.A.est <- logistic(apply(posta$a , 2 , mean))
d$propsurv.B.est <- logistic(apply(postb$a , 2 , mean))

# display raw proportions surviving in each tank
plot(
  d$propsurv ,
  ylim = c(0, 1) ,
  pch = 16 ,
  xaxt = "n" ,
  xlab = "tank" ,
  ylab = "proportion survival" ,
  col = rangi2
)
axis( 1 , at=c(1,16,32,48) , labels=c(1,16,32,48) )

# overlay posterior means
points( d$propsurv.A.est, col = "black" )
points( d$propsurv.B.est, col = "red" )


# mark posterior mean probability across tanks
abline( h=mean(inv_logit(posta$a)) , lty=2, col = "black" )
abline( h=mean(inv_logit(postb$a)) , lty=2, col = "red" )

# draw vertical dividers between tank densities
abline( v=16.5 , lwd=0.5 )
abline( v=32.5 , lwd=0.5 )
text( 8 , 0 , "small tanks" )
text( 16+8 , 0 , "medium tanks" )
text( 32+8 , 0 , "large tanks" )

mean(d$propsurv.A.est - mean(inv_logit(posta$a)))
mean(d$propsurv.B.est - mean(inv_logit(postb$a)))
```


### 12E2. Make the following model into a multilevel model.

$$
y_i \sim Binomial(1, p_i) \\
logit(p_i) = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(0, 10) \\
\beta \sim Normal(0, 1)
$$

$$
y_i \sim Binomial(1, p_i) \\
logit(p_i) = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(\bar\alpha, \sigma) \\
\bar\alpha \sim Normal(0, 10) \\
\sigma \sim Exponential(1) \\
\beta \sim Normal(0, 1)
$$

### 12E3. Make the following model into a multilevel model.

$$
y_i \sim Normal(\mu_i, \sigma) \\
\mu_i = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(0, 10) \\
\beta \sim Normal(0, 1) \\
\sigma \sim HalfCauchy(0, 2)
$$

$$
y_i \sim Normal(\mu_i, \sigma) \\
\mu_i = \alpha_{group[i]} + \beta x_i \\
\alpha_{group} \sim Normal(\bar\alpha, \sigma_\alpha) \\
\bar\alpha \sim Normal(0, 10) \\
\sigma_\alpha \sim Exponential(1) \\
\beta \sim Normal(0, 1) \\
\sigma \sim HalfCauchy(0, 2)
$$

### 12M1. Revisit the Reed frog survival data, data(reedfrogs), and add the predation and size treatment variables to the varying intercepts model. Consider models with either main effect alone, both main effects, as well as a model including both and their interaction. Instead of focusing on inferences about these two predictor variables, focus on the inferred variation across tanks. Explain why it changes as it does across models.

```{r}
d <- reedfrogs
d$tank <- 1:nrow(d)

dat <- list(S = d$surv,
            N = d$density,
            tank = d$tank)

m12.1 <- ulam(
  alist(
    S ~ dbinom(N , p),
    logit(p) <- a[tank],
    a[tank] ~ dnorm(a_bar , sigma),
    a_bar ~ dnorm(0 , 1.5),
    sigma ~ dexp(1)
  ),
  data = dat ,
  chains = 4,
  cores = 3,
  log_lik = TRUE,
  iter = 2500
)


dat2 <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  pred = ifelse(d$pred == "no", 0L, 1L)
)

m12.1a <- ulam(
  alist(
    S ~ dbinom(N , p) ,
    logit(p) <- a[tank] + bP * pred ,
    a[tank] ~ dnorm(a_bar , sigma) ,
    bP ~ dnorm(0 , 1), 
    a_bar ~ dnorm(0 , 1.5) ,
    sigma ~ dexp(1)
  ),
  data = dat2 ,
  chains = 4 ,
  cores = 3,
  log_lik = TRUE,
  iter = 2500
)

dat3 <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  sze = ifelse(d$pred == "small", 0L, 1L)
)

m12.1b <- ulam(
  alist(
    S ~ dbinom(N , p) ,
    logit(p) <- a[tank] + bS * sze,
    a[tank] ~ dnorm(a_bar , sigma) ,
    a_bar ~ dnorm(0 , 1.5) ,
    bS ~ dnorm(0 , 1),
    sigma ~ dexp(1)
  ),
  data = dat3 ,
  chains = 4 ,
  cores = 3,
  log_lik = TRUE,
  iter = 2500
)

dat4 <- list(
  S = d$surv,
  N = d$density,
  tank = d$tank,
  pred = ifelse(d$pred == "no", 0L, 1L),
  sze = ifelse(d$pred == "small", 0L, 1L)
)


m12.1c <- ulam(
  alist(
    S ~ dbinom(N , p) ,
    logit(p) <- a[tank] + bP * pred + bS * sze,
    a[tank] ~ dnorm(a_bar , sigma) ,
    a_bar ~ dnorm(0 , 1.5) ,
    c(bS,bP) ~ dnorm(0 , 1),
    sigma ~ dexp(1)
  ),
  data = dat4 ,
  chains = 4 ,
  cores = 3,
  log_lik = TRUE,
  iter = 2500
)

m12.1d <- ulam(
  alist(
    S ~ dbinom(N , p) ,
    logit(p) <- a[tank] + bP * pred + bS * sze + bPS * sze * pred,
    a[tank] ~ dnorm(a_bar , sigma) ,
    a_bar ~ dnorm(0 , 1.5) ,
    c(bS,bP,bPS) ~ dnorm(0 , 1),
    sigma ~ dexp(1)
  ),
  data = dat4 ,
  chains = 4 ,
  cores = 3,
  log_lik = TRUE,
  iter = 2500
)

compare(m12.1,m12.1a,m12.1b,m12.1c,m12.1d)

abc <- coeftab(m12.1,m12.1a,m12.1b,m12.1c,m12.1d)

abc@coefs %>% tail(5)
```

The variation across tanks is reduced when predation is added to the model. The effect does not seem to occur when only size is considered though.

### 12M2. Compare the models you fit just above, using WAIC. Can you reconcile the differences in WAIC with the posterior distributions of the models?

```{r}
compare(m12.1,m12.1a,m12.1b,m12.1c,m12.1d)
```

They all look pretty equal despite the models containing predation having a lower tank to tank variance.


### 12H1. In 1980, a typical Bengali woman could have 5 or more children in her lifetime. By the year 200, a typical Bengali woman had only 2 or 3. You’re going to look at a historical set of data, when contraception was widely available but many families chose not to use it. These data reside in data(bangladesh) and come from the 1988 Bangladesh Fertility Survey. Each row is one of 1934 women. There are six variables, but you can focus on three of them for this practice problem:

  (1) district: ID number of administrative district each woman resided in
  (2) use.contraception: An indicator (0/1) of whether the woman was using contraception
  (3) urban: An indicator (0/1) of whether the woman lived in a city, as opposed to living in a rural area

### The first thing to do is ensure that the cluster variable, district, is a contiguous set of integers. Recall that these values will be index values inside the model. If there are gaps, you’ll have parameters for which there is no data to inform them. Worse, the model probably won’t run. Look at the unique values of the district variable:

```{r}
data(bangladesh)
d <- bangladesh
sort(unique(d$district))
```

### District 54 is absent. So district isn’t yet a good index variable, because it’s not contiguous. This is easy to fix. Just make a new variable that is contiguous. This is enough to do it:

```{r}
d$district_id <- as.integer(as.factor(d$district))
sort(unique(d$district_id))
```

### Now there are 60 values, contiguous integers 1 to 60.

### Now, focus on predicting use.contraception, clustered by district_id. Do not include urban just yet. Fit both (1) a traditional fixed-effects model that uses dummy variables for district and (2) a multilevel model with varying intercepts for district. Plot the predicted proportions of women in each district using contraception, for both the fixed-effects model and the varying-effects model. That is, make a plot in which district ID is on the horizontal axis and expected proportion using contraception is on the vertical. Make one plot for each model, or layer them on the same plot, as you prefer. How do the models disagree? Can you explain the pattern of disagreement? In particular, can you explain the most extreme cases of disagreement, both why they happen where they do and why the models reach different inferences?

```{r}
head(d)

dat <- list(
  did = d$district_id,
  concep = d$use.contraception
)

h12.1a <- ulam(
  alist(
    concep ~ dbinom(1, p),
    logit(p) <- a[did],
    a[did] ~ dnorm(0, 1.5)
  ), data = dat, cores = 3, chains = 4, iter = 2500, log_lik = TRUE
)

h12.1b <- ulam(
  alist(
    concep ~ dbinom(1, p),
    logit(p) <- a[did],
    a[did] ~ dnorm(a_bar, sigma),
    a_bar ~ dnorm(0, 1.5),
    sigma ~ dexp(1)
  ), data = dat, cores = 3, chains = 4, iter = 2500, log_lik = TRUE
)

precis(h12.1a, depth = 2)
precis(h12.1b, depth = 2)
compare(h12.1a,h12.1b)

pred_dat <- data.frame(did = unique(d$district_id))
predsa <- link(h12.1a,pred_dat)
predsb <- link(h12.1b,pred_dat)

results <- data.frame(district = unique(d$district_id),
                      fixed = apply(predsa, 2, mean),
                      varying = apply(predsb, 2, mean)
                      )
head(results)
results <- results %>%
  gather(key = "model", value = "mu", fixed:varying)
head(results)

ggplot(results, aes(x = district, y = mu, color = model)) +
  geom_point() +
  scale_color_manual(values=c('black','blue')) +
  geom_hline(yintercept = results %>%
               filter(model == "fixed") %>%
               select(mu) %>%
               summarise(mean = mean(mu)) %>%
               .$mean) +
  geom_hline(yintercept = results %>%
               filter(model == "varying") %>%
               select(mu) %>%
               summarise(mean = mean(mu)) %>%
               .$mean,
             color = 'blue'
             )

## Add in urban as a variable

dat2 <- list(
  did = d$district_id,
  concep = d$use.contraception,
  urban = d$urban
)

h12.1c <- ulam(
  alist(
    concep ~ dbinom(1, p),
    logit(p) <- a[did] + bU*urban,
    a[did] ~ dnorm(0, 1.5),
    bU ~ dnorm(0, 1)
  ), data = dat2, cores = 3, chains = 4, iter = 2500, log_lik = TRUE
)

h12.1d <- ulam(
  alist(
    concep ~ dbinom(1, p),
    logit(p) <- a[did] + bU*urban,
    a[did] ~ dnorm(a_bar, sigma),
    bU ~ dnorm(0, 1),
    a_bar ~ dnorm(0, 1.5),
    sigma ~ dexp(1)
  ), data = dat2, cores = 3, chains = 4, iter = 2500, log_lik = TRUE
)

precis(h12.1c, depth = 2)
precis(h12.1d, depth = 2)
compare(h12.1c,h12.1d)
compare(h12.1a,h12.1b,h12.1c,h12.1d)

pred_dat2 <- data.frame(did = rep(unique(d$district_id), each = 2),
                       urban = rep(c(0,1), times = 60))
predsc <- link(h12.1c,pred_dat2)
predsd <- link(h12.1d,pred_dat2)

results2 <- data.frame(district = pred_dat2$did,
                      urban = pred_dat2$urban,
                      fixed = apply(predsc, 2, mean),
                      varying = apply(predsd, 2, mean)
                      )

head(results2)
results2 <- results2 %>%
  gather(key = "model", value = "mu", fixed:varying)
head(results2)

ggplot(results2, aes(x = district, y = mu, color = model,shape = as.factor(urban))) +
  geom_point() +
  scale_color_manual(values=c('black','blue')) +
  geom_hline(yintercept = results2 %>%
               filter(model == "fixed" & urban == 1) %>%
               select(mu) %>%
               summarise(mean = mean(mu)) %>%
               .$mean) +
  geom_hline(yintercept = results2 %>%
               filter(model == "varying" & urban == 1) %>%
               select(mu) %>%
               summarise(mean = mean(mu)) %>%
               .$mean,
             color = 'blue'
             ) +
  geom_hline(yintercept = results2 %>%
               filter(model == "fixed" & urban == 0) %>%
               select(mu) %>%
               summarise(mean = mean(mu)) %>%
               .$mean,
             linetype = "dashed") +
  geom_hline(yintercept = results2 %>%
               filter(model == "varying" & urban == 0) %>%
               select(mu) %>%
               summarise(mean = mean(mu)) %>%
               .$mean,
             color = 'blue',
             linetype = "dashed"
             )
```

