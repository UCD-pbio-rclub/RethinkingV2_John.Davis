---
title: "Chapter 3"
author: "John D."
date: "1/26/2021"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
R.version

library(keras)
library(tidyverse)
library(ISLR)
library(tree)
library(randomForest)
library(MASS)
library(gbm)
```

# Load OJ

```{r}
# Set up the data
dat <- OJ
summary(dat)
dim(dat)
# 0 = CH 1 = MM
nn_labels <- as.numeric(dat$Purchase) - 1
nn_data <- dat[,-1]
set.seed(1)
train <- sample(1:nrow(dat), 800)
tree.train <- dat[train,]
tree.test <- dat[-train,]
nn_train_data <- data.matrix(nn_data[train,])
nn_test_data <- data.matrix(nn_data[-train,])
nn_train_label <- data.matrix(nn_labels[train])
nn_test_label <- data.matrix(nn_labels[-train])
```

# OJ Model
```{r}
## Remove predictors
nn_data.small <- nn_data[,c(9,12,7,16,14)]
nn_train_data <- data.matrix(nn_data.small[train,])
nn_test_data <- data.matrix(nn_data.small[-train,])

# Try other methods
model <- keras_model_sequential() %>%
  layer_dense(units = 32, activation = "relu", input_shape = dim(nn_train_data)[[2]]) %>%
  layer_dense(units = 16, activation = "relu") %>%
  layer_dense(units = 8, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")

model %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("accuracy")
)
model %>% fit(nn_train_data, nn_train_label, epochs = 20, verbose = 0)

results <- model %>% evaluate(nn_test_data, nn_test_label)
results
```

# Cancer Dataset
```{r}
# Refresh workspace
rm(list = ls())
gc()
```

# Load Cancer data
```{r}
dat_labels <- read_csv("cancer_labels.csv")
dat_data <- read_csv("cancer_data.csv")
```

```{r}
# process data
# remove sample names
unique(dat_labels$Class)
dat_labels$X1 <- NULL
dat_data$X1 <- NULL
dat_labels$Class <- as.numeric(as.factor(dat_labels$Class)) - 1

# Remove low variation data
novariation <- apply(dat_data, 2, sd)==0
dat_data <- dat_data[,!novariation]

lowexpression <- apply(dat_data, 2, mean) < 1
dat_data <- dat_data[, !lowexpression]

# Split into test and train
index <- sample(x = 1:nrow(dat_data), size =  600, replace = F)
train_data <- as.matrix(dat_data[index,])
test_data <- as.matrix(dat_data[-index,])

train_targets <- as.integer(dat_labels$Class[index])
test_targets <- as.integer(dat_labels$Class[-index])

# Scale data using train as base
mean <- apply(train_data, 2, mean)
std <- apply(train_data, 2, sd)
train_data <- scale(train_data, center = mean, scale = std)
test_data <- scale(test_data, center = mean, scale = std)

rm(mean, std, index, novariation, lowexpression, dat_data, dat_labels)
gc()

dim(test_data)
length(test_targets)

dim(train_data)
length(train_targets)
```

```{r}
# Build models
# Function
build_model <- function() {
  model <- keras_model_sequential() %>%
    layer_dense(units = 64, activation = "relu", input_shape = dim(train_data)[[2]]) %>%
    layer_dense(units = 64, activation = "relu") %>%
    layer_dense(units = 5, activation = "softmax")
  model %>% compile(
    optimizer = "rmsprop",
    loss = "sparse_categorical_crossentropy",
    metrics = c("accuracy")
  )
}
```

```{r}
model <- build_model()
model %>% fit(train_data, train_targets, epochs = 5)
result <- model %>% evaluate(test_data, test_targets)
result
```

# Parkinsons data
```{r}
# Refresh workspace
rm(list = ls())
gc()
```

* subject - Integer that uniquely identifies each subject
* age - Subject age
* sex - Subject gender '0' - male, '1' - female
* test_time - Time since recruitment into the trial. The integer part is the number of days since recruitment.
* motor_UPDRS - Clinician's motor UPDRS score, linearly interpolated
* total_UPDRS - Clinician's total UPDRS score, linearly interpolated
* Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequency
* Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitude
* NHR,HNR - Two measures of ratio of noise to tonal components in the voice
* RPDE - A nonlinear dynamical complexity measure
* DFA - Signal fractal scaling exponent
* PPE - A nonlinear measure of fundamental frequency variation

```{r}
park.data <- read_csv("parkinsons_updrs.data")
summary(park.data)
```

```{r}
# Subset data train on 80% of patients, k validation with 5 folds
set.seed(123)
k <- 5
indices <- sample(1:max(park.data$`subject#`))
folds <- cut(indices, breaks = k, labels = FALSE)
```

```{r}
# Loop to process_data
parkinson_model <- function(k = 5, epochs = 20) {
  # Divide data by patients
  indices <- sample(1:max(park.data$`subject#`))
  folds <- cut(indices, breaks = k, labels = FALSE)
  validation_scores <- c()
  
  # Split data sets
  for (i in 1:k) {
    # Prep data
    validation_indices <- which(folds == i, arr.ind = TRUE)
    training_data <-
      park.data[!(park.data$`subject#` %in% validation_indices),-c(1, 6)]
    validation_data <-
      park.data[park.data$`subject#` %in% validation_indices,-c(1, 6)]
    
    # Normalize data
    mean <- apply(training_data, 2, mean)
    std <- apply(training_data, 2, sd)
    training_data <-
      scale(training_data, center = mean, scale = std)
    validation_data <-
      scale(validation_data, center = mean, scale = std)
    
    # Normalize targets
    training_targets <-
      park.data[!(park.data$`subject#` %in% validation_indices), 6] %>%
      pull(total_UPDRS) %>% as.numeric()
    validation_targets <-
      park.data[park.data$`subject#` %in% validation_indices, 6] %>%
      pull(total_UPDRS) %>% as.numeric()
    mean <- mean(training_targets, na.rm = T)
    std <- sd(training_targets, na.rm = T)
    training_targets <-
      scale(training_targets, center = mean, scale = std)
    validation_targets <-
      scale(validation_targets, center = mean, scale = std)
    
    # Prep model
    model <- keras_model_sequential() %>%
      layer_dense(
        units = 64,
        activation = "relu",
        input_shape = dim(training_data)[[2]]
      ) %>%
      layer_dense(units = 64, activation = "relu") %>%
      layer_dense(units = 1)
    
    # Compile model
    model %>% compile(optimizer = "rmsprop",
                      loss = "mse",
                      metrics = c("mae"))
    # Fit model
    model %>% fit(training_data, training_targets, epochs = epochs, verbose = 0)
    # Test model
    results <-
      model %>% evaluate(validation_data, validation_targets)
    validation_scores <- c(validation_scores, results[2])
  }
  # Sum error
  validation_score <- mean(validation_scores)
  validation_score
}
```

```{r}
parkinson_model()
```

mae of .33

# Removing motor_UPDRS

```{r}
# Loop to process_data
parkinson_model2 <- function(k = 5, epochs = 20) {
  # Divide data by patients
  indices <- sample(1:max(park.data$`subject#`))
  folds <- cut(indices, breaks = k, labels = FALSE)
  validation_scores <- c()
  
  # Split data sets
  for (i in 1:k) {
    # Prep data
    validation_indices <- which(folds == i, arr.ind = TRUE)
    training_data <-
      park.data[!(park.data$`subject#` %in% validation_indices),-c(1, 5, 6)]
    validation_data <-
      park.data[park.data$`subject#` %in% validation_indices,-c(1, 5, 6)]
    
    # Normalize data
    mean <- apply(training_data, 2, mean)
    std <- apply(training_data, 2, sd)
    training_data <-
      scale(training_data, center = mean, scale = std)
    validation_data <-
      scale(validation_data, center = mean, scale = std)
    
    # Normalize targets
    training_targets <-
      park.data[!(park.data$`subject#` %in% validation_indices), 6] %>%
      pull(total_UPDRS) %>% as.numeric()
    validation_targets <-
      park.data[park.data$`subject#` %in% validation_indices, 6] %>%
      pull(total_UPDRS) %>% as.numeric()
    mean <- mean(training_targets, na.rm = T)
    std <- sd(training_targets, na.rm = T)
    training_targets <-
      scale(training_targets, center = mean, scale = std)
    validation_targets <-
      scale(validation_targets, center = mean, scale = std)
    
    # Prep model
    model <- keras_model_sequential() %>%
      layer_dense(
        units = 64,
        activation = "relu",
        input_shape = dim(training_data)[[2]]
      ) %>%
      layer_dense(units = 64, activation = "relu") %>%
      layer_dense(units = 1)
    
    # Compile model
    model %>% compile(optimizer = "rmsprop",
                      loss = "mse",
                      metrics = c("mae"))
    # Fit model
    model %>% fit(training_data, training_targets, epochs = epochs, verbose = 0)
    # Test model
    results <-
      model %>% evaluate(validation_data, validation_targets)
    validation_scores <- c(validation_scores, results[2])
  }
  # Sum error
  validation_score <- mean(validation_scores)
  cat("Average MAE is", validation_score)
}
```

```{r}
parkinson_model2()
```

```{r}
sd(park.data$total_UPDRS)
mean(park.data$total_UPDRS)
```

Definitely within a standard deviation