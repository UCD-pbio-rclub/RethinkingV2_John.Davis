---
title: "11_1_2019_HW"
author: "John D."
date: "November 1, 2019"
output: 
  html_document: 
    keep_md: yes
---




```r
library(tidyverse)
```

```
## -- Attaching packages ----------------------------------------------------- tidyverse 1.2.1 --
```

```
## v ggplot2 3.2.1     v purrr   0.3.3
## v tibble  2.1.3     v dplyr   0.8.3
## v tidyr   1.0.0     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.4.0
```

```
## -- Conflicts -------------------------------------------------------- tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()
```

```r
library(rethinking)
```

```
## Loading required package: rstan
```

```
## Loading required package: StanHeaders
```

```
## rstan (Version 2.19.2, GitRev: 2e1f913d3ca3)
```

```
## For execution on a local, multicore CPU with excess RAM we recommend calling
## options(mc.cores = parallel::detectCores()).
## To avoid recompilation of unchanged Stan programs, we recommend calling
## rstan_options(auto_write = TRUE)
```

```
## For improved execution time, we recommend calling
## Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
## although this causes Stan to throw an error on a few processors.
```

```
## 
## Attaching package: 'rstan'
```

```
## The following object is masked from 'package:tidyr':
## 
##     extract
```

```
## Loading required package: parallel
```

```
## Loading required package: dagitty
```

```
## rethinking (Version 1.90)
```

```
## 
## Attaching package: 'rethinking'
```

```
## The following object is masked from 'package:purrr':
## 
##     map
```

```
## The following object is masked from 'package:stats':
## 
##     rstudent
```

```r
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
```

## 10E1. If an event has probability 0.35, what are the log-odds of this event?


```r
logit(0.35)
```

```
## [1] -0.6190392
```

## 10E2. If an event has log-odds 3.2, what is the probability of this event?


```r
inv_logit(3.2)
```

```
## [1] 0.9608343
```

## 10E3. Suppose that a coefficient in a logistic regression has value 1.7. What does this imply about the proportional change in odds of the outcome?

A one unit change in the variable while have a 1.7 unit change in the log of the odds.

## 10M1. As explained in the chapter, binomial data can be organized in aggregated and disaggregated forms, without any impact on inference. But the likelihood of the data does change when the data are converted between the two formats. Can you explain why?

The multiplicity in the aggregated data causes the aggregated data likelihood to be different from the disaggregated data likelihood. Looking at counts vs individual trials.

## 1. The data in data(NWOGrants) are outcomes for scientific funding applications for the Netherlands Organization for Scientific Research (NWO) from 2010-2012. These data have a very similar structure to the UCBAdmit data discussed in Chapter 11.
### I want you to consider a similar question: What are the total and indirect causal effects of gender on grant awards? Consider a mediation path (a pipe) through `discipline`. Draw the corresponding DAG and then use one or more binomial GLMs to answer the question.
### What is your causal interpretation? If NWO's goal is to equilize rates of funding between the genders, what type of intervention would be most effective?


```r
library(dagitty)
data("NWOGrants")
d <- NWOGrants
head(d)
```

```
##          discipline gender applications awards
## 1 Chemical sciences      m           83     22
## 2 Chemical sciences      f           39     10
## 3 Physical sciences      m          135     26
## 4 Physical sciences      f           39      9
## 5           Physics      m           67     18
## 6           Physics      f            9      2
```

```r
summary(d)
```

```
##                discipline gender  applications        awards     
##  Chemical sciences  :2    f:9    Min.   :  9.00   Min.   : 2.00  
##  Earth/life sciences:2    m:9    1st Qu.: 69.75   1st Qu.:14.00  
##  Humanities         :2           Median :130.50   Median :24.00  
##  Interdisciplinary  :2           Mean   :156.83   Mean   :25.94  
##  Medical sciences   :2           3rd Qu.:219.75   3rd Qu.:32.75  
##  Physical sciences  :2           Max.   :425.00   Max.   :65.00  
##  (Other)            :6
```

```r
# Build DAG
dag <- dagitty( "dag {
                G -> A
                G -> D
                D -> A
                }")
coordinates(dag) <- list(x = c(G=0,D=0.5,A=1), y = c(G=0,D=-0.5,A=0))
plot(dag)
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-4-1.png)<!-- -->

```r
# Model 1 without conditioning on discipline
dat_slim <- list(
  awards = d$awards,
  gender = ifelse(d$gender == "m", 1L,2L),
  applications = d$applications
)

dat_slim
```

```
## $awards
##  [1] 22 10 26  9 18  2 33 32 30 13 12 17 38 18 65 47 46 29
## 
## $gender
##  [1] 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2
## 
## $applications
##  [1]  83  39 135  39  67   9 230 166 189  62 105  78 156 126 425 409 245
## [18] 260
```

```r
model_1 <- ulam(
  alist(
    awards ~ dbinom(applications, p),
    logit(p) <- a[gender],
    a[gender] ~ dnorm(0 , 1.5)
  ), data = dat_slim, cores = 4, chains = 4, iter = 5000
)

traceplot(model_1)
precis(model_1, depth = 2)
```

```
##           mean         sd      5.5%     94.5%    n_eff     Rhat
## a[1] -1.533210 0.06352322 -1.634812 -1.432467 6948.278 1.000342
## a[2] -1.738785 0.08250014 -1.871119 -1.609710 6537.489 1.000046
```

```r
post <- extract.samples(model_1)
diff_a <- post$a[,1] - post$a[,2]
diff_p <- inv_logit(post$a[,1]) - inv_logit(post$a[,2])
precis(list(diff_a = diff_a , diff_p = diff_p))
```

```
##              mean         sd        5.5%      94.5%
## diff_a 0.20557541 0.10544726 0.040458022 0.37485634
## diff_p 0.02794405 0.01420042 0.005652861 0.05059457
##                                                                                               histogram
## diff_a                         <U+2581><U+2581><U+2582><U+2587><U+2587><U+2583><U+2581><U+2581><U+2581>
## diff_p <U+2581><U+2581><U+2581><U+2582><U+2585><U+2587><U+2587><U+2583><U+2581><U+2581><U+2581><U+2581>
```

```r
par(mfrow=c(1,1))
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-4-2.png)<!-- -->

```r
postcheck( model_1 , n=1e4)
# draw lines connecting points from same dept
d$disc_id <- rep( 1:9 , each=2 )
for ( i in 1:9 ) {
  x <- 1 + 2*(i-1)
  y1 <- d$awards[x]/d$applications[x]
  y2 <- d$awards[x+1]/d$applications[x+1]
  lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2)
  text( x+0.5 , (y1+y2)/2 + 0.05 , d$discipline[x] , cex=0.8 , col=rangi2 )
}
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-4-3.png)<!-- -->

```r
# Model 2, condition on discipline

dat_slim2 <- list(
  awards = d$awards,
  gender = ifelse(d$gender == "m", 1L,2L),
  applications = d$applications,
  discipline = d$disc_id
)

model_2 <- ulam(
  alist(
    awards ~ dbinom(applications, p),
    logit(p) <- a[gender] + d[discipline],
    a[gender] ~ dnorm(0 , 1.5),
    d[discipline] ~ dnorm(0, 1.5)
  ), data = dat_slim2, cores = 4, chains = 4, iter = 5000
)

traceplot(model_2)
precis(model_2, depth = 2)
```

```
##            mean        sd       5.5%      94.5%    n_eff     Rhat
## a[1] -1.1488167 0.4778601 -1.9172517 -0.3972842 688.2021 1.001621
## a[2] -1.2874382 0.4805419 -2.0571894 -0.5211492 710.4156 1.001457
## d[1]  0.1446592 0.5091205 -0.6543666  0.9732580 772.2864 1.001761
## d[2] -0.2082401 0.5070191 -1.0053967  0.6069236 759.6633 1.001412
## d[3]  0.1172136 0.5280044 -0.7270779  0.9586312 792.6753 1.001478
## d[4] -0.4261312 0.4897422 -1.1978325  0.3631024 734.5124 1.001301
## d[5] -0.3979519 0.4995222 -1.1835378  0.4129737 773.3638 1.001051
## d[6] -0.4714156 0.5087225 -1.2728739  0.3414473 819.2875 1.001002
## d[7] -0.1917271 0.4945369 -0.9778008  0.6003970 723.0445 1.001460
## d[8] -0.6485250 0.4846508 -1.4095918  0.1391745 714.5350 1.001552
## d[9] -0.5317081 0.4917620 -1.3136793  0.2552262 727.6062 1.001637
```

```r
post <- extract.samples(model_2)
diff_a <- post$a[,1] - post$a[,2]
diff_p <- inv_logit(post$a[,1]) - inv_logit(post$a[,2])
precis(list(diff_a = diff_a , diff_p = diff_p))
```

```
##              mean         sd         5.5%      94.5%
## diff_a 0.13862151 0.10655050 -0.030085070 0.30581681
## diff_p 0.02410064 0.01974727 -0.005084893 0.05687703
##                                                                               histogram
## diff_a         <U+2581><U+2581><U+2582><U+2585><U+2587><U+2585><U+2581><U+2581><U+2581>
## diff_p <U+2581><U+2581><U+2582><U+2587><U+2587><U+2583><U+2581><U+2581><U+2581><U+2581>
```

```r
par(mfrow=c(1,1))
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-4-4.png)<!-- -->

```r
postcheck( model_2 , n=1e4)
# draw lines connecting points from same dept
d$disc_id <- rep( 1:9 , each=2 )
for ( i in 1:9 ) {
  x <- 1 + 2*(i-1)
  y1 <- d$awards[x]/d$applications[x]
  y2 <- d$awards[x+1]/d$applications[x+1]
  lines( c(x,x+1) , c(y1,y2) , col=rangi2 , lwd=2)
  text( x+0.5 , (y1+y2)/2 + 0.05 , d$discipline[x] , cex=0.8 , col=rangi2 )
}
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-4-5.png)<!-- -->

```r
pg <- sapply( 1:9 , function(k)
  d$applications[d$disc_id==k]/sum(d$applications[d$disc_id==k]))

ag <- sapply( 1:9 , function(k)
  d$awards[d$disc_id==k]/sum(d$awards[d$disc_id==k]))

all <- d %>%
  cbind(., awarded = as.vector(ag[1:18]), applied = as.vector(pg[1:18]))

all %>% gather(key = Type, value = Value, awarded:applied) %>%
  mutate(Combination = paste0(gender,"_",Type)) %>%
  ggplot(., aes(x = discipline, y = Value, fill = Combination)) +
  geom_bar(stat = "identity", position = "dodge")
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-4-6.png)<!-- -->

Males have a higher award rate on average. When factoring discipline in, males still have a slight advantage over females. 


## 2. Suppose that the NWO Grants sample has an unobserved confound that influences both choice of discipline and the probability of an award. One example of such a confound could be the career stage of each applicant. Suppose that in some disciplines, junior scholars apply for most of the grants. In other disciplines, scholars from all career stages compete. As a result, career stage influences discipline as well as the probability of being awarded a grant.
### Add theses influences to your DAG from Problem 1. What happens now when you condition on discipline? Does it provide an un-confounded estimate of the direct path from gender to an award? Why or why not? Justify your answer with the back-door criterion. Hint: This is structually a lot like the grandparents-parents-children-neighborhoods example from a previous week.
### If you have trouble thinking this through, try simulating fake data, assuming your DAG is true. Then analyze it using the model from Problem 1. What do you conclude? Is it possible for gender to have a real direct causal influence but for a regression conditioning on both gender and discipline to suggest zero influence?


```r
# Build DAG
dag <- dagitty( "dag {
                G -> A
                G -> D
                D -> A
                S -> D
                S -> A
                }")
coordinates(dag) <- list(x = c(G=0,D=0.5,A=0.5,S=1), y = c(G=0,D=0,A=-0.5,S=0))
plot(dag)
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-5-1.png)<!-- -->

```r
# Sim the effect of Stage

set.seed(452)
N <- 10000
G <- rbinom(N,1,0.5)
S <- rbinom(N,1,0.5)
D <- rbinom(N,1, inv_logit(G + S))
A <- rbinom(N,1, inv_logit(0.25*G + 0.75*D + 0.75*S - 1.25)) # max = .62; min = .22
dat_slim <- list(
  A = A,
  D = D,
  G = G
)

model_3 <- ulam(
  alist(
    A ~ dbinom(1,p),
    logit(p) <- a + d*D + g*G,
    a ~ dnorm(0,.5),
    d ~ dnorm(0,.5),
    g ~ dnorm(0,.5)
  ), data = dat_slim, chains = 4, cores = 4, iter = 5000
)

traceplot(model_3)
```

![](11_1_2019_HW_files/figure-html/unnamed-chunk-5-2.png)<!-- -->

```r
precis(model_3, depth = 2)
```

```
##         mean         sd       5.5%      94.5%    n_eff     Rhat
## a -1.0102523 0.04352831 -1.0805808 -0.9404212 3956.361 1.001102
## d  0.9478275 0.04791848  0.8734271  1.0249049 4394.012 1.001064
## g  0.1845129 0.04132464  0.1190395  0.2503263 5951.917 1.000206
```

Gender now appears to have a stronger influence on awards
