08\_10\_2020\_HW
================
John D.
8/10/2020

``` r
library(rethinking)
```

    ## Loading required package: rstan

    ## Warning: package 'rstan' was built under R version 3.6.3

    ## Loading required package: StanHeaders

    ## Loading required package: ggplot2

    ## Warning: package 'ggplot2' was built under R version 3.6.3

    ## rstan (Version 2.19.3, GitRev: 2e1f913d3ca3)

    ## For execution on a local, multicore CPU with excess RAM we recommend calling
    ## options(mc.cores = parallel::detectCores()).
    ## To avoid recompilation of unchanged Stan programs, we recommend calling
    ## rstan_options(auto_write = TRUE)

    ## For improved execution time, we recommend calling
    ## Sys.setenv(LOCAL_CPPFLAGS = '-march=corei7 -mtune=corei7')
    ## although this causes Stan to throw an error on a few processors.

    ## Loading required package: parallel

    ## Loading required package: dagitty

    ## rethinking (Version 1.93)

    ## 
    ## Attaching package: 'rethinking'

    ## The following object is masked from 'package:stats':
    ## 
    ##     rstudent

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------ tidyverse 1.3.0 --

    ## v tibble  3.0.1     v dplyr   0.8.5
    ## v tidyr   1.0.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0
    ## v purrr   0.3.4

    ## Warning: package 'tibble' was built under R version 3.6.3

    ## Warning: package 'tidyr' was built under R version 3.6.3

    ## Warning: package 'purrr' was built under R version 3.6.3

    ## Warning: package 'dplyr' was built under R version 3.6.3

    ## Warning: package 'forcats' was built under R version 3.6.3

    ## -- Conflicts --------------------------- tidyverse_conflicts() --
    ## x tidyr::extract() masks rstan::extract()
    ## x dplyr::filter()  masks stats::filter()
    ## x dplyr::lag()     masks stats::lag()
    ## x purrr::map()     masks rethinking::map()

16H1, 16H2, 16H3, 16H4 and 16H5

## 16M3. Use prior predictive simulations to investigate the Lynx-hare model. Begin with the priorsin the chapter. Which population dynamics do these produce? Can you suggest any improvements to the priors, on the basis of your simulations?

## 16H1. Modify the Panda nut opening model so that male and female chimpanzees have different maximum adult body mass. The sex variable in data(Panda\_nuts) provides the information you need. Be sure to incorporate the fact that you know, prior to seeing the data, that males are on average larger than females at maturity.

## 16H2. Now return to the Panda nut model and try to incorporate individual differences. There are two parameters, ϕ and k, which plausibly vary by individual. Pick one of these, allow it to vary by individual, and use partial pooling to avoid overfitting. The variable chimpanzee in data(Panda\_nuts) tells you which observations belong to which individuals.

## 16H3. The chapter asserts that a typical, geocentric time series model might be one that uses lag variables. Here you’ll fit such a model and compare it to ODE model in the chapter. An autoregressive time series uses earlier values of the state variables to predict new values of the same variables. These earlier values are called lag variables. You can construct the lag variables here with:

``` r
data(Lynx_Hare)
dat_ar1 <- list(
  L = Lynx_Hare$Lynx[2:21],
  L_lag1 = Lynx_Hare$Lynx[1:20],
  H = Lynx_Hare$Hare[2:21],
  H_lag1 = Lynx_Hare$Hare[1:20]
)
```

## Now you can use L\_lag1 and H\_lag1 as predictors of the outcomes L and H. Like this:

  
![
L\_t \\sim LogNormal(log \\mu\_{L,t}, \\sigma\_L) \\\\
\\mu\_{L,t} = \\alpha\_L + \\beta\_{LL}L\_{t-1} + \\beta\_{LH}H\_{t-1}
\\\\
H\_t \\sim LogNormal(log \\mu\_{H,t}, \\sigma\_H) \\\\
\\mu\_{H,t} = \\alpha\_H + \\beta\_{HH}H\_{t-1} + \\beta\_{HL}L\_{t-1}
](https://latex.codecogs.com/png.latex?%0AL_t%20%5Csim%20LogNormal%28log%20%5Cmu_%7BL%2Ct%7D%2C%20%5Csigma_L%29%20%5C%5C%0A%5Cmu_%7BL%2Ct%7D%20%3D%20%5Calpha_L%20%2B%20%5Cbeta_%7BLL%7DL_%7Bt-1%7D%20%2B%20%5Cbeta_%7BLH%7DH_%7Bt-1%7D%20%5C%5C%0AH_t%20%5Csim%20LogNormal%28log%20%5Cmu_%7BH%2Ct%7D%2C%20%5Csigma_H%29%20%5C%5C%0A%5Cmu_%7BH%2Ct%7D%20%3D%20%5Calpha_H%20%2B%20%5Cbeta_%7BHH%7DH_%7Bt-1%7D%20%2B%20%5Cbeta_%7BHL%7DL_%7Bt-1%7D%0A
"
L_t \\sim LogNormal(log \\mu_{L,t}, \\sigma_L) \\\\
\\mu_{L,t} = \\alpha_L + \\beta_{LL}L_{t-1} + \\beta_{LH}H_{t-1} \\\\
H_t \\sim LogNormal(log \\mu_{H,t}, \\sigma_H) \\\\
\\mu_{H,t} = \\alpha_H + \\beta_{HH}H_{t-1} + \\beta_{HL}L_{t-1}
")  
\#\# where Lt−1 and Ht−1 are the lag variables. Use ulam() to fit this
model. Be careful of the priors of the α and β parameters. Compare the
posterior predictions of the autoregressive model to the ODE model in
the chapter. How do the predictions differ? Can you explain why, using
the structures of the models?

## 16H4. Adapt the autoregressive model to use a two-step lag variable. This means that Lt−2 and Ht−2, in addition to Lt−1 and Ht−1, will appear in the equation for µ. This implies that prediction depends upon not only what happened just before now, but also on what happened two time steps ago. How does this model perform, compared to the ODE model?

## 16H5. Population dynamic models are typically very difficult to fit to empirical data. The Lynx-hare example in the chapter was easy, partly because the data are unusually simple and partly because the chapter did the difficult prior selection for you. Here’s another data set that will impress upon you both how hard the task can be and how badly Lotka-Volterra fits empirical data in general. The data in data(Mites) are numbers of predator and prey mites living on fruit.222 Model these data using the same Lotka-Volterra ODE system from the chapter. These data are actual counts of individuals, not just their pelts. You will need to adapt the Stan code in data(Lynx\_Hare\_model). Note that the priors will need to be rescaled, because the outcome variables are on a different scale. Prior predictive simulation will help. Keep in mind as well that the time variable and the birth and death parameters go together. If you rescale the time dimension, that implies you must also rescale the parameters.
