08\_10\_2020\_Notes
================
John D.
8/10/2020

``` r
library(rethinking)
```

    ## Loading required package: rstan

    ## Warning: package 'rstan' was built under R version 3.6.3

    ## Loading required package: StanHeaders

    ## Loading required package: ggplot2

    ## Warning: package 'ggplot2' was built under R version 3.6.3

    ## rstan (Version 2.19.3, GitRev: 2e1f913d3ca3)

    ## For execution on a local, multicore CPU with excess RAM we recommend calling
    ## options(mc.cores = parallel::detectCores()).
    ## To avoid recompilation of unchanged Stan programs, we recommend calling
    ## rstan_options(auto_write = TRUE)

    ## For improved execution time, we recommend calling
    ## Sys.setenv(LOCAL_CPPFLAGS = '-march=corei7 -mtune=corei7')
    ## although this causes Stan to throw an error on a few processors.

    ## Loading required package: parallel

    ## Loading required package: dagitty

    ## rethinking (Version 1.93)

    ## 
    ## Attaching package: 'rethinking'

    ## The following object is masked from 'package:stats':
    ## 
    ##     rstudent

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------------ tidyverse 1.3.0 --

    ## v tibble  3.0.1     v dplyr   0.8.5
    ## v tidyr   1.0.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0
    ## v purrr   0.3.4

    ## Warning: package 'tibble' was built under R version 3.6.3

    ## Warning: package 'tidyr' was built under R version 3.6.3

    ## Warning: package 'purrr' was built under R version 3.6.3

    ## Warning: package 'dplyr' was built under R version 3.6.3

    ## Warning: package 'forcats' was built under R version 3.6.3

    ## -- Conflicts --------------------------- tidyverse_conflicts() --
    ## x tidyr::extract() masks rstan::extract()
    ## x dplyr::filter()  masks stats::filter()
    ## x dplyr::lag()     masks stats::lag()
    ## x purrr::map()     masks rethinking::map()

# 16\. Generalized Linear Madness

## 16.1. Geometric people

### 16.1.1. The scientific model

### 16.1.2. The statistical model

``` r
data(Howell1)
d <- Howell1
# scale observed variables
d$w <- d$weight / mean(d$weight)
d$h <- d$height / mean(d$height)
```

``` r
m16.1 <- ulam(
  alist(
    w ~ dlnorm(mu , sigma),
    exp(mu) <- 3.141593 * k * p ^ 2 * h ^ 3,
    p ~ beta(2 , 18),
    k ~ exponential(0.5),
    sigma ~ exponential(1)
  ),
  data = d ,
  chains = 4 ,
  cores = 4
)

precis(m16.1)
```

    ##            mean          sd      5.5%      94.5%    n_eff      Rhat
    ## p     0.2442600 0.056592520 0.1647635  0.3426302 691.6862 0.9994093
    ## k     5.9148564 2.836503812 2.5614169 11.0815619 673.7713 1.0017018
    ## sigma 0.2067551 0.005990304 0.1971846  0.2162467 832.3033 1.0007672

``` r
pairs(m16.1)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.2-1.png)<!-- -->

``` r
h_seq <- seq(from = 0 ,
             to = max(d$h) ,
             length.out = 30)
w_sim <- sim(m16.1 , data = list(h = h_seq))
mu_mean <- apply(w_sim , 2 , mean)
w_CI <- apply(w_sim , 2 , PI)
plot(
  d$h ,
  d$w ,
  xlim = c(0, max(d$h)) ,
  ylim = c(0, max(d$w)) ,
  col = rangi2 ,
  lwd = 2 ,
  xlab = "height (scaled)" ,
  ylab = "weight (scaled)"
)
lines(h_seq , mu_mean)
shade(w_CI , h_seq)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.3-1.png)<!-- -->

### 16.1.3. GLM in disguise

## 16.2. Hidden minds and observed behavior

``` r
data(Boxes)
precis(Boxes)
```

    ##                     mean        sd 5.5% 94.5%
    ## y              2.1208267 0.7279860    1     3
    ## gender         1.5055644 0.5003669    1     2
    ## age            8.0302067 2.4979055    5    13
    ## majority_first 0.4848967 0.5001696    0     1
    ## culture        3.7519873 1.9603189    1     8
    ##                                                                                                                       histogram
    ## y                                              <U+2583><U+2581><U+2581><U+2581><U+2587><U+2581><U+2581><U+2581><U+2581><U+2585>
    ## gender                                         <U+2587><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2587>
    ## age                                            <U+2587><U+2583><U+2585><U+2583><U+2583><U+2583><U+2582><U+2582><U+2582><U+2581>
    ## majority_first                                 <U+2587><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2581><U+2587>
    ## culture        <U+2583><U+2582><U+2581><U+2587><U+2581><U+2582><U+2581><U+2582><U+2581><U+2582><U+2581><U+2581><U+2581><U+2581>

``` r
table( Boxes$y ) / length( Boxes$y )
```

    ## 
    ##         1         2         3 
    ## 0.2114467 0.4562798 0.3322734

### 16.2.1. The scientific model

``` r
set.seed(7)
N <- 30 # number of children

# half are random
# sample from 1,2,3 at random for each
y1 <- sample(1:3 , size = N / 2 , replace = TRUE)

# half follow majority
y2 <- rep(2 , N / 2)

# combine and shuffle y1 and y2
y <- sample(c(y1, y2))

# count the 2s
sum(y == 2) / N
```

    ## [1] 0.7333333

### 16.2.2. The statistical model

### 16.2.3. Coding the statistical model

``` r
data(Boxes_model)
cat(Boxes_model)
```

    ## 
    ## data{
    ##     int N;
    ##     int y[N];
    ##     int majority_first[N];
    ## }
    ## parameters{
    ##     simplex[5] p;
    ## }
    ## model{
    ##     vector[5] phi;
    ##     
    ##     // prior
    ##     p ~ dirichlet( rep_vector(4,5) );
    ##     
    ##     // probability of data
    ##     for ( i in 1:N ) {
    ##         if ( y[i]==2 ) phi[1]=1; else phi[1]=0; // majority
    ##         if ( y[i]==3 ) phi[2]=1; else phi[2]=0; // minority
    ##         if ( y[i]==1 ) phi[3]=1; else phi[3]=0; // maverick
    ##         phi[4]=1.0/3.0;                         // random
    ##         if ( majority_first[i]==1 )             // follow first
    ##             if ( y[i]==2 ) phi[5]=1; else phi[5]=0;
    ##         else
    ##             if ( y[i]==3 ) phi[5]=1; else phi[5]=0;
    ##         
    ##         // compute log( p_s * Pr(y_i|s )
    ##         for ( j in 1:5 ) phi[j] = log(p[j]) + log(phi[j]);
    ##         // compute average log-probability of y_i
    ##         target += log_sum_exp( phi );
    ##     }
    ## }

``` r
# prep data
dat_list <- list(
  N = nrow(Boxes),
  y = Boxes$y,
  majority_first = Boxes$majority_first
)

# run the sampler
m16.2 <-
  stan(
    model_code = Boxes_model ,
    data = dat_list ,
    chains = 3 ,
    cores = 3
  )

# show marginal posterior for p
p_labels <-
  c("1 Majority",
    "2 Minority",
    "3 Maverick",
    "4 Random",
    "5 Follow First")
plot(precis(m16.2, 2) , labels = p_labels)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.8-1.png)<!-- -->

### 16.2.4. State space models

## 16.3. Ordinary differential nut cracking

``` r
data(Panda_nuts)
```

### 16.3.1. Scientific model

### 16.3.2. Statistical mode

``` r
N <- 1e4
phi <- rlnorm(N , log(1) , 0.1)
k <- rlnorm(N , log(2), 0.25)
theta <- rlnorm(N , log(5) , 0.25)
# relative grow curve
plot(
  NULL ,
  xlim = c(0, 1.5) ,
  ylim = c(0, 1) ,
  xaxt = "n" ,
  xlab = "age" ,
  ylab = "body mass"
)
at <- c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5)
axis(1 , at = at , labels = round(at * max(Panda_nuts$age)))
for (i in 1:20)
  curve((1 - exp(-k[i] * x)) ,
        add = TRUE ,
        col = grau() ,
        lwd = 1.5)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.10-1.png)<!-- -->

``` r
# implied rate of nut opening curve
plot(
  NULL ,
  xlim = c(0, 1.5) ,
  ylim = c(0, 1.2) ,
  xaxt = "n" ,
  xlab = "age" ,
  ylab = "nuts per second"
)
at <- c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5)
axis(1 , at = at , labels = round(at * max(Panda_nuts$age)))
for (i in 1:20)
  curve(phi[i] * (1 - exp(-k[i] * x)) ^ theta[i] ,
        add = TRUE ,
        col = grau() ,
        lwd = 1.5)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.10-2.png)<!-- -->

``` r
dat_list <- list(
  n = as.integer(Panda_nuts$nuts_opened),
  age = Panda_nuts$age / max(Panda_nuts$age),
  seconds = Panda_nuts$seconds
)
m16.4 <- ulam(
  alist(
    n ~ poisson(lambda),
    lambda <- seconds * phi * (1 - exp(-k * age)) ^ theta,
    phi ~ lognormal(log(1) , 0.1),
    k ~ lognormal(log(2) , 0.25),
    theta ~ lognormal(log(5) , 0.25)
  ),
  data = dat_list ,
  chains = 4
)
```

    ## 
    ## SAMPLING FOR MODEL 'fc81d2d8cb9f308e125283324fd5881c' NOW (CHAIN 1).
    ## Chain 1: 
    ## Chain 1: Gradient evaluation took 0 seconds
    ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
    ## Chain 1: Adjust your expectations accordingly!
    ## Chain 1: 
    ## Chain 1: 
    ## Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)
    ## Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)
    ## Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)
    ## Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)
    ## Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)
    ## Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)
    ## Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)
    ## Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)
    ## Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)
    ## Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)
    ## Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)
    ## Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)
    ## Chain 1: 
    ## Chain 1:  Elapsed Time: 0.397 seconds (Warm-up)
    ## Chain 1:                0.293 seconds (Sampling)
    ## Chain 1:                0.69 seconds (Total)
    ## Chain 1: 
    ## 
    ## SAMPLING FOR MODEL 'fc81d2d8cb9f308e125283324fd5881c' NOW (CHAIN 2).
    ## Chain 2: 
    ## Chain 2: Gradient evaluation took 0 seconds
    ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
    ## Chain 2: Adjust your expectations accordingly!
    ## Chain 2: 
    ## Chain 2: 
    ## Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)
    ## Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)
    ## Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)
    ## Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)
    ## Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)
    ## Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)
    ## Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)
    ## Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)
    ## Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)
    ## Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)
    ## Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)
    ## Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)
    ## Chain 2: 
    ## Chain 2:  Elapsed Time: 0.349 seconds (Warm-up)
    ## Chain 2:                0.364 seconds (Sampling)
    ## Chain 2:                0.713 seconds (Total)
    ## Chain 2: 
    ## 
    ## SAMPLING FOR MODEL 'fc81d2d8cb9f308e125283324fd5881c' NOW (CHAIN 3).
    ## Chain 3: 
    ## Chain 3: Gradient evaluation took 0 seconds
    ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
    ## Chain 3: Adjust your expectations accordingly!
    ## Chain 3: 
    ## Chain 3: 
    ## Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)
    ## Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)
    ## Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)
    ## Chain 3: Iteration: 300 / 1000 [ 30%]  (Warmup)
    ## Chain 3: Iteration: 400 / 1000 [ 40%]  (Warmup)
    ## Chain 3: Iteration: 500 / 1000 [ 50%]  (Warmup)
    ## Chain 3: Iteration: 501 / 1000 [ 50%]  (Sampling)
    ## Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)
    ## Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)
    ## Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)
    ## Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)
    ## Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)
    ## Chain 3: 
    ## Chain 3:  Elapsed Time: 0.317 seconds (Warm-up)
    ## Chain 3:                0.325 seconds (Sampling)
    ## Chain 3:                0.642 seconds (Total)
    ## Chain 3: 
    ## 
    ## SAMPLING FOR MODEL 'fc81d2d8cb9f308e125283324fd5881c' NOW (CHAIN 4).
    ## Chain 4: 
    ## Chain 4: Gradient evaluation took 0 seconds
    ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
    ## Chain 4: Adjust your expectations accordingly!
    ## Chain 4: 
    ## Chain 4: 
    ## Chain 4: Iteration:   1 / 1000 [  0%]  (Warmup)
    ## Chain 4: Iteration: 100 / 1000 [ 10%]  (Warmup)
    ## Chain 4: Iteration: 200 / 1000 [ 20%]  (Warmup)
    ## Chain 4: Iteration: 300 / 1000 [ 30%]  (Warmup)
    ## Chain 4: Iteration: 400 / 1000 [ 40%]  (Warmup)
    ## Chain 4: Iteration: 500 / 1000 [ 50%]  (Warmup)
    ## Chain 4: Iteration: 501 / 1000 [ 50%]  (Sampling)
    ## Chain 4: Iteration: 600 / 1000 [ 60%]  (Sampling)
    ## Chain 4: Iteration: 700 / 1000 [ 70%]  (Sampling)
    ## Chain 4: Iteration: 800 / 1000 [ 80%]  (Sampling)
    ## Chain 4: Iteration: 900 / 1000 [ 90%]  (Sampling)
    ## Chain 4: Iteration: 1000 / 1000 [100%]  (Sampling)
    ## Chain 4: 
    ## Chain 4:  Elapsed Time: 0.392 seconds (Warm-up)
    ## Chain 4:                0.321 seconds (Sampling)
    ## Chain 4:                0.713 seconds (Total)
    ## Chain 4:

``` r
post <- extract.samples(m16.4)
plot(
  NULL ,
  xlim = c(0, 1) ,
  ylim = c(0, 1.5) ,
  xlab = "age" ,
  ylab = "nuts per second" ,
  xaxt = "n"
)
at <- c(0, 0.25, 0.5, 0.75, 1, 1.25, 1.5)
axis(1 , at = at , labels = round(at * max(Panda_nuts$age)))
# raw data
pts <- dat_list$n / dat_list$seconds
point_size <- normalize(dat_list$seconds)
points(
  jitter(dat_list$age) ,
  pts ,
  col = rangi2 ,
  lwd = 2 ,
  cex = point_size * 3
)
# 30 posterior curves
for (i in 1:30)
  with(post ,
       curve(phi[i] * (1 - exp(-k[i] * x)) ^ theta[i] , add = TRUE , col = grau()))
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.12-1.png)<!-- -->

### 16.3.3. Covariates and individual differences

## 16.4. Population dynamics

``` r
data(Lynx_Hare)
plot(
  1:21 ,
  Lynx_Hare[, 3] ,
  ylim = c(0, 90) ,
  xlab = "year" ,
  ylab = "thousands of pelts" ,
  xaxt = "n" ,
  type = "l" ,
  lwd = 1.5
)
at <- c(1, 11, 21)
axis(1 , at = at , labels = Lynx_Hare$Year[at])
lines(1:21 , Lynx_Hare[, 2] , lwd = 1.5 , col = rangi2)
points(
  1:21 ,
  Lynx_Hare[, 3] ,
  bg = "black" ,
  col = "white" ,
  pch = 21 ,
  cex = 1.4
)
points(
  1:21 ,
  Lynx_Hare[, 2] ,
  bg = rangi2 ,
  col = "white" ,
  pch = 21 ,
  cex = 1.4
)
text(17 , 80 , "Lepus" , pos = 2)
text(19 , 50 , "Lynx" , pos = 2 , col = rangi2)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.13-1.png)<!-- -->

### 16.4.1. The scientific model

``` r
sim_lynx_hare <- function(n_steps , init , theta , dt = 0.002) {
  L <- rep(NA, n_steps)
  H <- rep(NA, n_steps)
  L[1] <- init[1]
  H[1] <- init[2]
  for (i in 2:n_steps) {
    H[i] <- H[i - 1] + dt * H[i - 1] * (theta[1] - theta[2] * L[i - 1])
    L[i] <- L[i - 1] + dt * L[i - 1] * (theta[3] * H[i - 1] - theta[4])
  }
  return(cbind(L, H))
}
```

``` r
theta <- c(0.5 , 0.05 , 0.025 , 0.5)
z <- sim_lynx_hare(1e4 , as.numeric(Lynx_Hare[1, 2:3]) , theta)
plot(
  z[, 2] ,
  type = "l" ,
  ylim = c(0, max(z[, 2])) ,
  lwd = 2 ,
  xaxt = "n" ,
  ylab = "number (thousands)" ,
  xlab = ""
)
lines(z[, 1] , col = rangi2 , lwd = 2)
mtext("time" , 1)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.15-1.png)<!-- -->

### 16.4.2. The statistical model

``` r
N <- 1e4
Ht <- 1e4
p <- rbeta(N,2,18)
h <- rbinom( N , size=Ht , prob=p )
h <- round( h/1000 , 2 )
dens( h , xlab="thousand of pelts" , lwd=2 )
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.16-1.png)<!-- -->

``` r
data(Lynx_Hare_model)
cat(Lynx_Hare_model)
```

    ## functions {
    ##   real[] dpop_dt( real t,                 // time
    ##                 real[] pop_init,          // initial state {lynx, hares}
    ##                 real[] theta,             // parameters
    ##                 real[] x_r, int[] x_i) {  // unused
    ##     real L = pop_init[1];
    ##     real H = pop_init[2];
    ##     real bh = theta[1];
    ##     real mh = theta[2];
    ##     real ml = theta[3];
    ##     real bl = theta[4];
    ##     // differential equations
    ##     real dH_dt = (bh - mh * L) * H;
    ##     real dL_dt = (bl * H - ml) * L;
    ##     return { dL_dt , dH_dt };
    ##   }
    ## }
    ## data {
    ##   int<lower=0> N;              // number of measurement times
    ##   real<lower=0> pelts[N,2];    // measured populations
    ## }
    ## transformed data{
    ##   real times_measured[N-1];    // N-1 because first time is initial state
    ##   for ( i in 2:N ) times_measured[i-1] = i;
    ## }
    ## parameters {
    ##   real<lower=0> theta[4];      // { bh, mh, ml, bl }
    ##   real<lower=0> pop_init[2];   // initial population state
    ##   real<lower=0> sigma[2];      // measurement errors
    ##   real<lower=0,upper=1> p[2];  // trap rate
    ## }
    ## transformed parameters {
    ##   real pop[N, 2];
    ##   pop[1,1] = pop_init[1];
    ##   pop[1,2] = pop_init[2];
    ##   pop[2:N,1:2] = integrate_ode_rk45(
    ##     dpop_dt, pop_init, 0, times_measured, theta,
    ##     rep_array(0.0, 0), rep_array(0, 0),
    ##     1e-5, 1e-3, 5e2);
    ## }
    ## model {
    ##   // priors
    ##   theta[{1,3}] ~ normal( 1 , 0.5 );    // bh,ml
    ##   theta[{2,4}] ~ normal( 0.05, 0.05 ); // mh,bl
    ##   sigma ~ exponential( 1 );
    ##   pop_init ~ lognormal( log(10) , 1 );
    ##   p ~ beta(40,200);
    ##   // observation model
    ##   // connect latent population state to observed pelts
    ##   for ( t in 1:N )
    ##     for ( k in 1:2 )
    ##       pelts[t,k] ~ lognormal( log(pop[t,k]*p[k]) , sigma[k] );
    ## }
    ## generated quantities {
    ##   real pelts_pred[N,2];
    ##   for ( t in 1:N )
    ##     for ( k in 1:2 )
    ##       pelts_pred[t,k] = lognormal_rng( log(pop[t,k]*p[k]) , sigma[k] );
    ## }

``` r
set.seed(123)
dat_list <- list(N = nrow(Lynx_Hare),
                 pelts = Lynx_Hare[, 2:3])

m16.5 <-
  stan(
    model_code = Lynx_Hare_model ,
    data = dat_list ,
    chains = 3 ,
    cores = 3 ,
    control = list(adapt_delta = 0.95)
  )
```

    ## Warning in validityMethod(object): The following variables have
    ## undefined values: pelts_pred[1,1],The following variables have
    ## undefined values: pelts_pred[2,1],The following variables have
    ## undefined values: pelts_pred[3,1],The following variables have
    ## undefined values: pelts_pred[4,1],The following variables have
    ## undefined values: pelts_pred[5,1],The following variables have
    ## undefined values: pelts_pred[6,1],The following variables have
    ## undefined values: pelts_pred[7,1],The following variables have
    ## undefined values: pelts_pred[8,1],The following variables have
    ## undefined values: pelts_pred[9,1],The following variables have
    ## undefined values: pelts_pred[10,1],The following variables have
    ## undefined values: pelts_pred[11,1],The following variables have
    ## undefined values: pelts_pred[12,1],The following variables have
    ## undefined values: pelts_pred[13,1],The following variables have
    ## undefined values: pelts_pred[14,1],The following variables have
    ## undefined values: pelts_pred[15,1],The following variables have
    ## undefined values: pelts_pred[16,1],The following variables have
    ## undefined values: pelts_pred[17,1],The following variables have
    ## undefined values: pelts_pred[18,1],The following variables have
    ## undefined values: pelts_pred[19,1],The following variables have
    ## undefined values: pelts_pred[20,1],The following variables have
    ## undefined values: pelts_pred[21,1],The following variables have
    ## undefined values: pelts_pred[1,2],The following variables have
    ## undefined values: pelts_pred[2,2],The following variables have
    ## undefined values: pelts_pred[3,2],The following variables have
    ## undefined values: pelts_pred[4,2],The following variables have
    ## undefined values: pelts_pred[5,2],The following variables have
    ## undefined values: pelts_pred[6,2],The following variables have
    ## undefined values: pelts_pred[7,2],The following variables have
    ## undefined values: pelts_pred[8,2],The following variables have undefined
    ## values: pelts_pred[9,2],The following variables have undefined values:
    ## pelts_pred[10,2],The following variables have undefined values:
    ## pelts_pred[11,2],The following variables have undefined values:
    ## pelts_pred[12,2],The following variables have undefined values:
    ## pelts_pred[13,2],The following variables have undefined values:
    ## pelts_pred[14,2],The following variables have undefined values:
    ## pelts_pred[15,2],The following variables have undefined values:
    ## pelts_pred[16,2],The following variables have undefined values:
    ## pelts_pred[17,2],The following variables have undefined values:
    ## pelts_pred[18,2],The following variables have undefined values:
    ## pelts_pred[19,2],The following variables have undefined values:
    ## pelts_pred[20,2],The following variables have undefined values:
    ## pelts_pred[21,2]. Many subsequent functions will not work correctly.

    ## Warning: There were 10 divergent transitions after warmup. Increasing adapt_delta above 0.95 may help. See
    ## http://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup

    ## Warning: There were 990 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See
    ## http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded

    ## Warning: There were 1 chains where the estimated Bayesian Fraction of Missing Information was low. See
    ## http://mc-stan.org/misc/warnings.html#bfmi-low

    ## Warning: Examine the pairs() plot to diagnose sampling problems

    ## Warning: The largest R-hat is NA, indicating chains have not mixed.
    ## Running the chains for more iterations may help. See
    ## http://mc-stan.org/misc/warnings.html#r-hat

    ## Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
    ## Running the chains for more iterations may help. See
    ## http://mc-stan.org/misc/warnings.html#bulk-ess

    ## Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
    ## Running the chains for more iterations may help. See
    ## http://mc-stan.org/misc/warnings.html#tail-ess

``` r
post <- extract.samples(m16.5)
pelts <- dat_list$pelts
plot(
  1:21 ,
  pelts[, 2] ,
  pch = 16 ,
  ylim = c(0, 120) ,
  xlab = "year" ,
  ylab = "thousands of pelts" ,
  xaxt = "n"
)
at <- c(1, 11, 21)
axis(1 , at = at , labels = Lynx_Hare$Year[at])
points(1:21 , pelts[, 1] , col = rangi2 , pch = 16)
# 21 time series from posterior
for (s in 1:21) {
  lines(1:21 ,
        post$pelts_pred[s, , 2] ,
        col = col.alpha("black", 0.2) ,
        lwd = 2)
  lines(1:21 ,
        post$pelts_pred[s, , 1] ,
        col = col.alpha(rangi2, 0.3) ,
        lwd = 2)
}
# text labels
text(17 , 90 , "Lepus" , pos = 2)
text(19 , 50 , "Lynx" , pos = 2 , col = rangi2)
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.19-1.png)<!-- -->

``` r
plot(
  NULL ,
  pch = 16 ,
  xlim = c(1, 21) ,
  ylim = c(0, 500) ,
  xlab = "year" ,
  ylab = "thousands of animals" ,
  xaxt = "n"
)
at <- c(1, 11, 21)
axis(1 , at = at , labels = Lynx_Hare$Year[at])
for (s in 1:21) {
  lines(1:21 ,
        post$pop[s, , 2] ,
        col = col.alpha("black", 0.2) ,
        lwd = 2)
  lines(1:21 , post$pop[s, , 1] , col = col.alpha(rangi2, 0.4) , lwd = 2)
}
```

![](08_10_2020_Notes_files/figure-gfm/R%20code%2016.20-1.png)<!-- -->

### 16.4.3. Lynx lessons

## 16.5. Summary
