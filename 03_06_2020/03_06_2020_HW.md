---
title: "03_06_2020_HW"
author: "John D."
date: "3/6/2020"
output: 
  html_document: 
    keep_md: yes
---




```r
library(rethinking)
```

```
## Loading required package: rstan
```

```
## Loading required package: StanHeaders
```

```
## Loading required package: ggplot2
```

```
## rstan (Version 2.19.2, GitRev: 2e1f913d3ca3)
```

```
## For execution on a local, multicore CPU with excess RAM we recommend calling
## options(mc.cores = parallel::detectCores()).
## To avoid recompilation of unchanged Stan programs, we recommend calling
## rstan_options(auto_write = TRUE)
```

```
## For improved execution time, we recommend calling
## Sys.setenv(LOCAL_CPPFLAGS = '-march=native')
## although this causes Stan to throw an error on a few processors.
```

```
## Loading required package: parallel
```

```
## Loading required package: dagitty
```

```
## rethinking (Version 1.93)
```

```
## 
## Attaching package: 'rethinking'
```

```
## The following object is masked from 'package:stats':
## 
##     rstudent
```

```r
library(tidyverse)
```

```
## -- Attaching packages ------------------------------------------------------------------------------- tidyverse 1.3.0 --
```

```
## v tibble  2.1.3     v dplyr   0.8.3
## v tidyr   1.0.0     v stringr 1.4.0
## v readr   1.3.1     v forcats 0.4.0
## v purrr   0.3.3
```

```
## -- Conflicts ---------------------------------------------------------------------------------- tidyverse_conflicts() --
## x tidyr::extract() masks rstan::extract()
## x dplyr::filter()  masks stats::filter()
## x dplyr::lag()     masks stats::lag()
## x purrr::map()     masks rethinking::map()
```

## 14E1. Add to the following model varying slopes on the predictor x.
shiny::includeHTML("https://latex.codecogs.com/gif.latex?y_i&space;\sim&space;Normal(\mu_i,&space;\sigma)&space;\\&space;\mu_i&space;=&space;\alpha_{group[i]}&space;&plus;&space;\beta&space;x_i&space;\\&space;\alpha_{group}&space;\sim&space;Normal(\alpha,&space;\sigma_\alpha)&space;\\&space;\alpha&space;\sim&space;Normal(0,&space;10)&space;\\&space;\beta&space;\sim&space;Normal(0,&space;1)&space;\\&space;\sigma&space;\sim&space;HalfCauchy(0,&space;2)&space;\\&space;\sigma_\alpha&space;\sim&space;HalfCauchy(0,&space;2)")

$$
y_i \sim Normal(\mu_i, \sigma) \\
\mu_i = \alpha_{group[i]} + \beta_{group} x_i \\
\left[ {\begin{array}{cc}
   \alpha_{group} \\
   \beta_{group}\ \\
  \end{array} } \right] \sim MVNormal(\left[ {\begin{array}{cc}
   \alpha \\
   \beta\ \\
  \end{array} } \right], S) \\
S =  \left[ {\begin{array}{cc}
   \sigma_\alpha & 0 \\
   0 & \sigma_\beta\ \\
  \end{array} } \right]
  R
  \left[ {\begin{array}{cc}
   \sigma_\alpha & 0 \\
   0 & \sigma_\beta\ \\
  \end{array} } \right] \\ 
\alpha \sim Normal(0, 10) \\
\beta \sim Normal(0, 1) \\
\sigma \sim HalfCauchy(0, 2)  \\
\sigma_\alpha \sim HalfCauchy(0, 2) \\
\sigma_\beta \sim HalfCauchy(0, 2) \\
R \sim LKJcorr(2)
$$
<!-- ## 14E2. Think up a context in which varying intercepts will be positively correlated with varying slopes. Provide a mechanistic explanation for the correlation -->

<!-- Movie theaters and their attendence throughout the day. Popular theaters will have a higher attendence at any time of the day compared to less popular theaters. At peak times like night, both theaters will have higher attendence with  the more popular theater having a larger increase. -->

<!-- ## 14E3. When is it possible for a varying slopes model to have fewer effective parameters (as estimated by WAIC or DIC) than the corresponding model with fixed (unpooled) slopes? Explain. -->

<!-- Highly correlated groups -->

<!-- ## 14M1. Repeat the café robot simulation from the beginning of the chapter. This time, set rho to zero, so that there is no correlation between intercepts and slopes. How does the posterior distribution of the correlation reflect this change in the underlying simulation? -->

<!-- ```{r} -->
<!-- a <- 3.5 # average morning wait time -->
<!-- b <- (-1) # average difference afternoon wait time -->
<!-- sigma_a <- 1 # std dev in intercepts -->
<!-- sigma_b <- 0.5 # std dev in slopes -->
<!-- rho <- (0) # correlation between intercepts and slopes -->
<!-- Mu <- c( a , b ) # Vector of means for multivariate -->
<!-- cov_ab <- sigma_a*sigma_b*rho # Create off diagonal value for 2X2 matrix -->
<!-- Sigma <- matrix( c(sigma_a^2,cov_ab,cov_ab,sigma_b^2) , ncol=2 ) # Make var-cov matrix -->
<!-- sigmas <- c(sigma_a,sigma_b) # standard deviations -->
<!-- N_cafes <- 20 -->
<!-- library(MASS) -->
<!-- set.seed(5) # used to replicate example -->
<!-- vary_effects <- mvrnorm( N_cafes, Mu, Sigma) -->
<!-- a_cafe <- vary_effects[,1] -->
<!-- b_cafe <- vary_effects[,2] -->
<!-- plot(a_cafe, b_cafe, col = rangi2, -->
<!--      xlab = "intercepts (a_cafe)", -->
<!--      ylab = "slopes (b_cafe)") -->
<!-- # overlay population distribution -->
<!-- library(ellipse) -->
<!-- for (l in c(0.1, 0.3, 0.5, 0.8, 0.99)) -->
<!--   lines(ellipse(Sigma, centre = Mu, level = l), col = col.alpha("black", 0.2)) -->
<!-- set.seed(22) -->
<!-- N_visits <- 10 -->
<!-- afternoon <- rep(0:1,N_visits*N_cafes/2) -->
<!-- cafe_id <- rep( 1:N_cafes , each=N_visits ) -->
<!-- mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon -->
<!-- sigma <- 0.5 # std dev within cafes -->
<!-- wait <- rnorm( N_visits*N_cafes , mu , sigma ) -->
<!-- d <- data.frame( cafe=cafe_id , afternoon=afternoon , wait=wait ) -->

<!-- m14.1M <- ulam( -->
<!--   alist( -->
<!--     wait ~ normal(mu , sigma), -->
<!--     mu <- a_cafe[cafe] + b_cafe[cafe] * afternoon, -->
<!--     c(a_cafe, b_cafe)[cafe] ~ multi_normal(c(a, b) , Rho , sigma_cafe), -->
<!--     a ~ normal(5, 2), -->
<!--     b ~ normal(-1, 0.5), -->
<!--     sigma_cafe ~ exponential(1), -->
<!--     sigma ~ exponential(1), -->
<!--     Rho ~ lkj_corr(2) -->
<!--   ) , -->
<!--   data = d, -->
<!--   chains = 4, -->
<!--   cores = 4 -->
<!-- ) -->

<!-- post <- extract.samples(m14.1M) -->
<!-- dens( post$Rho[,1,2] ) -->
<!-- ``` -->

<!-- It's mostly around 0, but tails do extend past |0.5| -->

<!-- Trying again with stronger eta -->
<!-- ```{r} -->
<!-- m14.1Ma <- ulam( -->
<!--   alist( -->
<!--     wait ~ normal(mu , sigma), -->
<!--     mu <- a_cafe[cafe] + b_cafe[cafe] * afternoon, -->
<!--     c(a_cafe, b_cafe)[cafe] ~ multi_normal(c(a, b) , Rho , sigma_cafe), -->
<!--     a ~ normal(5, 2), -->
<!--     b ~ normal(-1, 0.5), -->
<!--     sigma_cafe ~ exponential(1), -->
<!--     sigma ~ exponential(1), -->
<!--     Rho ~ lkj_corr(5) -->
<!--   ) , -->
<!--   data = d, -->
<!--   chains = 4, -->
<!--   cores = 4 -->
<!-- ) -->

<!-- post <- extract.samples(m14.1Ma) -->
<!-- dens( post$Rho[,1,2] ) -->
<!-- ``` -->

<!-- look at correlation of posterior -->
<!-- ```{r} -->
<!-- tail(precis(m14.1M, depth = 3), 4) -->
<!-- tail(precis(m14.1Ma, depth = 3), 4) -->
<!-- ``` -->

<!-- Looks like a correlation is about 0 -->

<!-- ## 14M2. Fit this multilevel model to the simulated café data: -->
<!-- $$ -->
<!-- W_i \sim Normal(\mu_i, \sigma) \\ -->
<!-- \mu_i = \alpha_{cafe[i]} + \beta_{cafe[i]}A_i \\ -->
<!-- \alpha_{cafe} \sim Normal(\alpha, \sigma_\alpha) \\ -->
<!-- \beta_{cafe} \sim Normal(\beta, \sigma_\beta) \\ -->
<!-- \alpha \sim Normal(0, 10) \\ -->
<!-- \beta \sim Normal(0, 10)  \\ -->
<!-- \sigma \sim HalfCauchy(0, 1) \\ -->
<!-- \sigma_\alpha \sim HalfCauchy(0, 1)  \\ -->
<!-- \sigma_\beta \sim HalfCauchy(0, 1) \\ -->
<!-- $$ -->

<!-- Use WAIC to compare this model to the model from the chapter, the one that uses a multi-variate -->
<!-- Gaussian prior. Explain the result. -->


<!-- ```{r} -->
<!-- # Bring original simulated data set in -->
<!-- a <- 3.5 # average morning wait time -->
<!-- b <- (-1) # average difference afternoon wait time -->
<!-- sigma_a <- 1 # std dev in intercepts -->
<!-- sigma_b <- 0.5 # std dev in slopes -->
<!-- rho <- (-0.7) # correlation between intercepts and slopes -->
<!-- Mu <- c( a , b ) # Vector of means for multivariate -->
<!-- cov_ab <- sigma_a*sigma_b*rho # Create off diagonal value for 2X2 matrix -->
<!-- Sigma <- matrix( c(sigma_a^2,cov_ab,cov_ab,sigma_b^2) , ncol=2 ) # Make var-cov matrix -->
<!-- sigmas <- c(sigma_a,sigma_b) # standard deviations -->
<!-- N_cafes <- 20 -->
<!-- set.seed(5) # used to replicate example -->
<!-- vary_effects <- mvrnorm( N_cafes, Mu, Sigma) -->
<!-- a_cafe <- vary_effects[,1] -->
<!-- b_cafe <- vary_effects[,2] -->
<!-- set.seed(22) -->
<!-- N_visits <- 10 -->
<!-- afternoon <- rep(0:1,N_visits*N_cafes/2) -->
<!-- cafe_id <- rep( 1:N_cafes , each=N_visits ) -->
<!-- mu <- a_cafe[cafe_id] + b_cafe[cafe_id]*afternoon -->
<!-- sigma <- 0.5 # std dev within cafes -->
<!-- wait <- rnorm( N_visits*N_cafes , mu , sigma ) -->
<!-- d <- data.frame( cafe=cafe_id , afternoon=afternoon , wait=wait ) -->

<!-- # orignal model -->
<!-- m14.1 <- ulam( -->
<!--   alist( -->
<!--     wait ~ normal(mu , sigma), -->
<!--     mu <- a_cafe[cafe] + b_cafe[cafe] * afternoon, -->
<!--     c(a_cafe, b_cafe)[cafe] ~ multi_normal(c(a, b) , Rho , sigma_cafe), -->
<!--     a ~ normal(5, 2), -->
<!--     b ~ normal(-1, 0.5), -->
<!--     sigma_cafe ~ exponential(1), -->
<!--     sigma ~ exponential(1), -->
<!--     Rho ~ lkj_corr(2) -->
<!--   ) , -->
<!--   data = d, -->
<!--   chains = 4, -->
<!--   cores = 4, -->
<!--   log_lik = T -->
<!-- ) -->

<!-- # new model -->
<!-- m14.2 <- ulam( -->
<!--   alist( -->
<!--     wait ~ normal(mu , sigma), -->
<!--     mu <- a_cafe[cafe] + b_cafe[cafe] * afternoon, -->
<!--     a_cafe[cafe] ~ normal(a, sigma_a), -->
<!--     b_cafe[cafe] ~ normal(b, sigma_b), -->
<!--     a ~ normal(5, 2), -->
<!--     b ~ normal(-1, 0.5), -->
<!--     sigma ~ exponential(1), -->
<!--     sigma_a ~ exponential(1), -->
<!--     sigma_b ~ exponential(1) -->
<!--   ) , -->
<!--   data = d, -->
<!--   chains = 4, -->
<!--   cores = 4, -->
<!--   log_lik = T -->
<!-- ) -->

<!-- compare(m14.1,m14.2) -->
<!-- ``` -->

<!-- Basically the same except the varying intercepts and slopes model does slightly better. New model had varying slopes and intercepts, just no covariance. -->
